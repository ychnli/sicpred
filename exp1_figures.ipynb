{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "from src import config_cesm\n",
    "from src.models.diagnostics import roll_metric\n",
    "\n",
    "CNAMES = [\"input2\", \"input3a\", \"input3b\", \"input3c\", \"input3d\", \"input4\"]\n",
    "\n",
    "def add_hatching(ax, significance_mask, x_edges, y_edges, hatch='///', edgecolor='k'):\n",
    "    Ny, Nx = significance_mask.shape\n",
    "\n",
    "    for i in range(Ny):\n",
    "        for j in range(Nx):\n",
    "            if significance_mask[i, j]:\n",
    "                rect = mpatches.Rectangle(\n",
    "                    (x_edges[j], y_edges[i]),\n",
    "                    x_edges[j+1] - x_edges[j],\n",
    "                    y_edges[i+1] - y_edges[i],\n",
    "                    hatch=hatch,\n",
    "                    fill=False,\n",
    "                    edgecolor=edgecolor,\n",
    "                    linewidth=0\n",
    "                )\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "def plot_markers(ax, exceeds_persistence, x_centers, y_centers):\n",
    "    for i in range(6):\n",
    "        for j in range(12):\n",
    "            if not exceeds_persistence[i,j]:\n",
    "                ax.plot(x_centers[j], y_centers[i], '.k', markersize=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = {}\n",
    "acc_agg = {}\n",
    "significance_ds = {}\n",
    "\n",
    "for cname in CNAMES:\n",
    "    acc_agg[cname] = xr.open_dataset(\n",
    "        os.path.join(config_cesm.PREDICTIONS_DIRECTORY, f\"exp1_{cname}\", \"diagnostics/acc_agg.nc\")\n",
    "    )[\"acc\"]\n",
    "    acc[cname] = xr.open_dataset(\n",
    "        os.path.join(config_cesm.PREDICTIONS_DIRECTORY, f\"exp1_{cname}\", \"diagnostics/acc.nc\")\n",
    "    )[\"acc\"]\n",
    "\n",
    "for cname in CNAMES:\n",
    "    if cname == \"input2\":\n",
    "        continue\n",
    "\n",
    "    significance_ds[cname] = xr.open_dataset(\n",
    "        os.path.join(config_cesm.ANALYSIS_RESULTS_DIRECTORY, f\"confidence_intervals/exp1_input2_exp1_{cname}_acc.nc\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot comparison of ACC (anomaly correlation coefficient)\n",
    "\n",
    "Each scorecard shows the ACC for predicting SIC at different months (x-axis) and lead times (y-axis). The results are aggregated over a test set of 4 CESM ensemble member historical simulations and 5 separate neural network initializations for each configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(config_cesm.ANALYSIS_RESULTS_DIRECTORY, \"exp1_inputs\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "for key, _ in cdicts.items():\n",
    "    acc[key].to_netcdf(os.path.join(save_dir, f\"ACC_{key}.nc\"))\n",
    "    acc_agg[key].to_netcdf(os.path.join(save_dir, f\"ACC_agg_{key}.nc\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved acc \n",
    "acc = {}\n",
    "acc_agg = {}\n",
    "\n",
    "save_dir = os.path.join(config_cesm.ANALYSIS_RESULTS_DIRECTORY, \"exp1_inputs\")\n",
    "for key in cdicts.keys():\n",
    "    acc[key] = xr.open_dataset(os.path.join(save_dir, f\"ACC_{key}.nc\"))[\"__xarray_dataarray_variable__\"]\n",
    "    acc_agg[key] = xr.open_dataset(os.path.join(save_dir, f\"ACC_agg_{key}.nc\"))[\"__xarray_dataarray_variable__\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute baseline forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import models \n",
    "\n",
    "print(f\"Loading persistence and climatology forecast...\")\n",
    "persistence_predictions = remove_climatology(models.anomaly_persistence(input2_cdict[\"DATA_SPLIT_SETTINGS\"], None).predictions, climatology_broadcast)\n",
    "climatology_predictions = remove_climatology(models.climatology_predictions(input2_cdict[\"DATA_SPLIT_SETTINGS\"], None).predictions, climatology_broadcast)\n",
    "\n",
    "print(f\"Computing ACC\")\n",
    "acc_persist = calculate_acc(persistence_predictions, targets, dim=(\"x\",\"y\"), aggregate=True)\n",
    "acc_clim = calculate_acc(climatology_predictions, targets, dim=(\"x\",\"y\"), aggregate=True)\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_persist_not_agg = calculate_acc(persistence_predictions, targets, dim=(\"x\",\"y\"), aggregate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: try this significance test w.r.t. the non-transformed ACCs (i.e., don't apply the Fisher $z$-transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_ds = {}\n",
    "\n",
    "for k in cdicts.keys(): \n",
    "    print(f\"Computing bootstrap significance test for {k}\")\n",
    "\n",
    "    # for the sea ice only config, test the difference with persistence\n",
    "    if k == \"input2\":\n",
    "        significance_ds[k] = bootstrap_acc_significance(acc[\"input2\"], acc_persist_not_agg)\n",
    "\n",
    "    # otherwise, the sea ice only config is the baseline\n",
    "    else:\n",
    "        significance_ds[k] = bootstrap_acc_significance(acc[\"input2\"], acc[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, ds in significance_ds.items():\n",
    "    significance_ds[k] = roll_acc(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(4,4), sharex=True)\n",
    "\n",
    "x = np.arange(13)\n",
    "y = np.arange(7)\n",
    "x_centers = (x[:-1] + x[1:]) / 2\n",
    "y_centers = (y[:-1] + y[1:]) / 2\n",
    "\n",
    "acc_input2 = acc_agg[\"input2\"].mean(\"nn_member_id\")\n",
    "acc_input4 = acc_agg[\"input4\"].mean(\"nn_member_id\")\n",
    "\n",
    "cax = axs[0].pcolormesh(x, y, acc_input2, cmap='Spectral', shading='flat', vmin=0, vmax=1)\n",
    "axs[0].set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "axs[0].set_ylabel(\"Lead time\")\n",
    "axs[0].set_title(f\"ACC for sea ice only\")\n",
    "\n",
    "cax2 = axs[1].pcolormesh(x, y, 100 * (acc_input4 - acc_input2) / acc_input2, cmap='RdBu', shading='flat', vmin=-10, vmax=10)\n",
    "axs[1].set_xticks(x_centers, labels=[\"J\",\"F\",\"M\",\"A\",\"M\",\"J\",\"J\",\"A\",\"S\",\"O\",\"N\",\"D\"])\n",
    "axs[1].set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "axs[1].set_ylabel(\"Lead time\")\n",
    "axs[1].set_title(\"ACC difference: add sst, psl, z500\")\n",
    "\n",
    "cbar_ax = fig.add_axes([1.04, 0.56, 0.03, 0.35])\n",
    "cbar_ax2 = fig.add_axes([1.04, 0.10, 0.03, 0.35])\n",
    "plt.colorbar(cax, cax=cbar_ax, label=r'ACC', orientation='vertical')\n",
    "plt.colorbar(cax2, cax=cbar_ax2, label=r'Percent change (%)', orientation='vertical')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"figures/cesm/exp1_ACC_diff_inputs_percent.jpg\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_VALUE_CUTOFF = 0.05\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import string\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(9,5), sharey=True)\n",
    "\n",
    "x = np.arange(13)\n",
    "y = np.arange(7)\n",
    "x_centers = (x[:-1] + x[1:]) / 2\n",
    "y_centers = (y[:-1] + y[1:]) / 2\n",
    "\n",
    "acc_input2 = acc_agg[\"input2\"].mean(\"nn_member_id\")\n",
    "input_configs = [\"input3a\", \"input3b\", \"input3c\", \"input3d\", \"input4\"]\n",
    "input_added = [\"sst\", \"slp\", \"z500\", \"t2m\", \"all\"]\n",
    "\n",
    "cax2 = axs[0,0].pcolormesh(x, y, acc_input2, cmap='Spectral', shading='flat', vmin=0, vmax=1)\n",
    "axs[0,0].set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "axs[0,0].set_ylabel(\"Lead time\")\n",
    "axs[0,0].set_title(f\"ACC (SIC only)\")\n",
    "axs[0,0].set_xticks(x_centers, labels=[\"J\",\"F\",\"M\",\"A\",\"M\",\"J\",\"J\",\"A\",\"S\",\"O\",\"N\",\"D\"])\n",
    "\n",
    "axs = axs.flatten()\n",
    "for i, ax in enumerate(axs[1:]):\n",
    "    input_config = input_configs[i]\n",
    "    cax = ax.pcolormesh(x, y, 100 * (acc_agg[input_config].mean(\"nn_member_id\") - acc_input2) / acc_input2, \n",
    "            cmap='RdBu', shading='flat', vmin=-15, vmax=15)\n",
    "    significance_mask = (significance_ds[input_config].p_value > P_VALUE_CUTOFF).astype(int)\n",
    "    add_hatching(ax, significance_mask, x, y)\n",
    "    ax.set_xticks(x_centers, labels=[\"J\",\"F\",\"M\",\"A\",\"M\",\"J\",\"J\",\"A\",\"S\",\"O\",\"N\",\"D\"])\n",
    "    ax.set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "    ax.set_title(f\"$\\Delta$ ACC: add {input_added[i]}\")\n",
    "\n",
    "axs[3].set_ylabel(\"Lead time\")\n",
    "\n",
    "cbar_ax = fig.add_axes([0.95, 0.2, 0.01, 0.6])\n",
    "cbar_ax2 = fig.add_axes([1.05, 0.2, 0.01, 0.6])\n",
    "\n",
    "plt.colorbar(cax, cax=cbar_ax2, label=r'Percent change (%)', orientation='vertical')\n",
    "plt.colorbar(cax2, cax=cbar_ax, label=r'ACC', orientation='vertical')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "panel_labels = list(string.ascii_lowercase)\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.annotate(\n",
    "        f\"{panel_labels[i]})\",\n",
    "        xy=(0, 1), xycoords=\"axes fraction\",\n",
    "        xytext=(-0.1, 1.03), textcoords=\"axes fraction\",\n",
    "        ha=\"left\", va=\"bottom\",\n",
    "        fontsize=11, fontweight=\"bold\"\n",
    "    )\n",
    "\n",
    "# plt.savefig(\"figures/cesm_new/exp1_ACC_percent.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_VALUE_CUTOFF = 0.01\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import string\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(9,5), sharey=True)\n",
    "\n",
    "x = np.arange(13)\n",
    "y = np.arange(7)\n",
    "x_centers = (x[:-1] + x[1:]) / 2\n",
    "y_centers = (y[:-1] + y[1:]) / 2\n",
    "\n",
    "acc_input2 = acc_agg[\"input2\"].mean(\"nn_member_id\")\n",
    "input_configs = [\"input3a\", \"input3b\", \"input3c\", \"input3d\", \"input4\"]\n",
    "input_added = [\"sst\", \"slp\", \"z500\", \"t2m\", \"all\"]\n",
    "\n",
    "cax2 = axs[0,0].pcolormesh(x, y, acc_input2, cmap='Spectral', shading='flat', vmin=0, vmax=1)\n",
    "axs[0,0].set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "axs[0,0].set_ylabel(\"Lead time\")\n",
    "axs[0,0].set_title(f\"ACC (SIC only)\")\n",
    "axs[0,0].set_xticks(x_centers, labels=[\"J\",\"F\",\"M\",\"A\",\"M\",\"J\",\"J\",\"A\",\"S\",\"O\",\"N\",\"D\"])\n",
    "\n",
    "axs = axs.flatten()\n",
    "for i, ax in enumerate(axs[1:]):\n",
    "    input_config = input_configs[i]\n",
    "    cax = ax.pcolormesh(x, y, acc_agg[input_config].mean(\"nn_member_id\") - acc_input2, \n",
    "            cmap='RdBu', shading='flat', vmin=-0.05, vmax=0.05)\n",
    "    significance_mask = (significance_ds[input_config].p_value > P_VALUE_CUTOFF).astype(int)\n",
    "    add_hatching(ax, significance_mask, x, y)\n",
    "    ax.set_xticks(x_centers, labels=[\"J\",\"F\",\"M\",\"A\",\"M\",\"J\",\"J\",\"A\",\"S\",\"O\",\"N\",\"D\"])\n",
    "    ax.set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "    ax.set_title(f\"$\\Delta$ ACC: add {input_added[i]}\")\n",
    "\n",
    "axs[3].set_ylabel(\"Lead time\")\n",
    "\n",
    "cbar_ax = fig.add_axes([0.95, 0.2, 0.01, 0.6])\n",
    "cbar_ax2 = fig.add_axes([1.05, 0.2, 0.01, 0.6])\n",
    "\n",
    "plt.colorbar(cax, cax=cbar_ax2, label=r'$\\Delta$ ACC (unitless)', orientation='vertical')\n",
    "plt.colorbar(cax2, cax=cbar_ax, label=r'ACC', orientation='vertical')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "panel_labels = list(string.ascii_lowercase)\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.annotate(\n",
    "        f\"{panel_labels[i]})\",\n",
    "        xy=(0, 1), xycoords=\"axes fraction\",\n",
    "        xytext=(-0.1, 1.03), textcoords=\"axes fraction\",\n",
    "        ha=\"left\", va=\"bottom\",\n",
    "        fontsize=11, fontweight=\"bold\"\n",
    "    )\n",
    "\n",
    "# plt.savefig(\"figures/cesm_new/exp1_ACC_absolute.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot RMSE comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = {}\n",
    "rmse_agg = {}\n",
    "significance_ds_rmse = {}\n",
    "\n",
    "for cname in CNAMES:\n",
    "    rmse_agg[cname] = xr.open_dataset(\n",
    "        os.path.join(config_cesm.PREDICTIONS_DIRECTORY, f\"exp1_{cname}\", \"diagnostics/rmse_agg.nc\")\n",
    "    )[\"rmse\"]\n",
    "    rmse[cname] = xr.open_dataset(\n",
    "        os.path.join(config_cesm.PREDICTIONS_DIRECTORY, f\"exp1_{cname}\", \"diagnostics/rmse.nc\")\n",
    "    )[\"rmse\"]\n",
    "\n",
    "for cname in CNAMES:\n",
    "    if cname == \"input2\":\n",
    "        continue\n",
    "\n",
    "    significance_ds_rmse[cname] = xr.open_dataset(\n",
    "        os.path.join(config_cesm.ANALYSIS_RESULTS_DIRECTORY, f\"confidence_intervals/exp1_input2_exp1_{cname}_rmse.nc\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_VALUE_CUTOFF = 0.01\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import string\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(9,5), sharey=True)\n",
    "\n",
    "x = np.arange(13)\n",
    "y = np.arange(7)\n",
    "x_centers = (x[:-1] + x[1:]) / 2\n",
    "y_centers = (y[:-1] + y[1:]) / 2\n",
    "\n",
    "rmse_input2 = rmse_agg[\"input2\"].mean(\"nn_member_id\")\n",
    "input_configs = [\"input3a\", \"input3b\", \"input3c\", \"input3d\", \"input4\"]\n",
    "input_added = [\"sst\", \"slp\", \"z500\", \"t2m\", \"all\"]\n",
    "\n",
    "cax2 = axs[0,0].pcolormesh(x, y, rmse_input2, cmap='Spectral_r', shading='flat', vmin=0.02, vmax=0.08)\n",
    "axs[0,0].set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "axs[0,0].set_ylabel(\"Lead time\")\n",
    "axs[0,0].set_title(f\"RMSE (SIC only)\")\n",
    "axs[0,0].set_xticks(x_centers, labels=[\"J\",\"F\",\"M\",\"A\",\"M\",\"J\",\"J\",\"A\",\"S\",\"O\",\"N\",\"D\"])\n",
    "\n",
    "axs = axs.flatten()\n",
    "for i, ax in enumerate(axs[1:]):\n",
    "    input_config = input_configs[i]\n",
    "    cax = ax.pcolormesh(x, y, rmse_agg[input_config].mean(\"nn_member_id\") - rmse_input2, \n",
    "            cmap='RdBu_r', shading='flat', vmin=-0.005, vmax=0.005)\n",
    "    significance_mask = (significance_ds_rmse[input_config].p_value > P_VALUE_CUTOFF).astype(int)\n",
    "    add_hatching(ax, significance_mask, x, y)\n",
    "    ax.set_xticks(x_centers, labels=[\"J\",\"F\",\"M\",\"A\",\"M\",\"J\",\"J\",\"A\",\"S\",\"O\",\"N\",\"D\"])\n",
    "    ax.set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "    ax.set_title(f\"$\\Delta$ RMSE: add {input_added[i]}\")\n",
    "\n",
    "axs[3].set_ylabel(\"Lead time\")\n",
    "\n",
    "cbar_ax = fig.add_axes([0.95, 0.2, 0.01, 0.6])\n",
    "cbar_ax2 = fig.add_axes([1.05, 0.2, 0.01, 0.6])\n",
    "\n",
    "plt.colorbar(cax, cax=cbar_ax2, label=r'$\\Delta$ RMSE', orientation='vertical')\n",
    "plt.colorbar(cax2, cax=cbar_ax, label=r'RMSE', orientation='vertical')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "panel_labels = list(string.ascii_lowercase)\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.annotate(\n",
    "        f\"{panel_labels[i]})\",\n",
    "        xy=(0, 1), xycoords=\"axes fraction\",\n",
    "        xytext=(-0.1, 1.03), textcoords=\"axes fraction\",\n",
    "        ha=\"left\", va=\"bottom\",\n",
    "        fontsize=11, fontweight=\"bold\"\n",
    "    )\n",
    "\n",
    "plt.savefig(\"figures/cesm_new/exp1_RMSE_absolute.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_VALUE_CUTOFF = 0.01\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import string\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(9,5), sharey=True)\n",
    "\n",
    "x = np.arange(13)\n",
    "y = np.arange(7)\n",
    "x_centers = (x[:-1] + x[1:]) / 2\n",
    "y_centers = (y[:-1] + y[1:]) / 2\n",
    "\n",
    "rmse_input2 = rmse_agg[\"input2\"].mean(\"nn_member_id\")\n",
    "input_configs = [\"input3a\", \"input3b\", \"input3c\", \"input3d\", \"input4\"]\n",
    "input_added = [\"sst\", \"slp\", \"z500\", \"t2m\", \"all\"]\n",
    "\n",
    "cax2 = axs[0,0].pcolormesh(x, y, rmse_input2, cmap='Spectral_r', shading='flat', vmin=0.02, vmax=0.08)\n",
    "axs[0,0].set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "axs[0,0].set_ylabel(\"Lead time\")\n",
    "axs[0,0].set_title(f\"RMSE (SIC only)\")\n",
    "axs[0,0].set_xticks(x_centers, labels=[\"J\",\"F\",\"M\",\"A\",\"M\",\"J\",\"J\",\"A\",\"S\",\"O\",\"N\",\"D\"])\n",
    "\n",
    "axs = axs.flatten()\n",
    "for i, ax in enumerate(axs[1:]):\n",
    "    input_config = input_configs[i]\n",
    "    cax = ax.pcolormesh(x, y, 100 * (rmse_agg[input_config].mean(\"nn_member_id\") - rmse_input2) / rmse_input2, \n",
    "            cmap='RdBu_r', shading='flat', vmin=-10, vmax=10)\n",
    "    significance_mask = (significance_ds_rmse[input_config].p_value > P_VALUE_CUTOFF).astype(int)\n",
    "    add_hatching(ax, significance_mask, x, y)\n",
    "    ax.set_xticks(x_centers, labels=[\"J\",\"F\",\"M\",\"A\",\"M\",\"J\",\"J\",\"A\",\"S\",\"O\",\"N\",\"D\"])\n",
    "    ax.set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "    ax.set_title(f\"$\\Delta$ RMSE: add {input_added[i]}\")\n",
    "\n",
    "axs[3].set_ylabel(\"Lead time\")\n",
    "\n",
    "cbar_ax = fig.add_axes([0.95, 0.2, 0.01, 0.6])\n",
    "cbar_ax2 = fig.add_axes([1.05, 0.2, 0.01, 0.6])\n",
    "\n",
    "plt.colorbar(cax, cax=cbar_ax2, label=r'Percent change RMSE', orientation='vertical')\n",
    "plt.colorbar(cax2, cax=cbar_ax, label=r'RMSE', orientation='vertical')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "panel_labels = list(string.ascii_lowercase)\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    ax.annotate(\n",
    "        f\"{panel_labels[i]})\",\n",
    "        xy=(0, 1), xycoords=\"axes fraction\",\n",
    "        xytext=(-0.1, 1.03), textcoords=\"axes fraction\",\n",
    "        ha=\"left\", va=\"bottom\",\n",
    "        fontsize=11, fontweight=\"bold\"\n",
    "    )\n",
    "\n",
    "plt.savefig(\"figures/cesm_new/exp1_RMSE_percent.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of normalization strategy on SST configuration skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiment_configs.exp1_inputs import input3a_dev\n",
    "from src.experiment_configs.exp1_inputs import input3a_std\n",
    "\n",
    "cdicts = {\n",
    "    \"input3a_dev\": input3a_dev, \n",
    "    \"input3a_std\": input3a_std, \n",
    "}\n",
    "\n",
    "cdict = load_globals(input3a_dev)\n",
    "climatology_broadcast = get_broadcast_climatology(cdict, \"test\")\n",
    "targets = load_targets(cdict, \"test\", add_climatology_to_anomaly=False)\n",
    "\n",
    "acc = {}\n",
    "acc_agg = {}\n",
    "\n",
    "num_nn_ens_members = 3\n",
    "for key, config in cdicts.items():\n",
    "    print(f\"computing ACC for {key}\")\n",
    "    cdict = load_globals(config) \n",
    "    pred = load_model_predictions(cdict, nn_ens_avg=False, climatology_broadcasted=None, \n",
    "                                    add_climatology_to_anomaly=False)\n",
    "\n",
    "    acc_temp_list = []\n",
    "    for i in range(num_nn_ens_members): \n",
    "        acc_temp = calculate_acc(pred.isel(nn_member_id=i), \n",
    "                            targets, dim=(\"x\",\"y\"), aggregate=False)\n",
    "        acc_temp_list.append(acc_temp)\n",
    "    acc[key] = xr.concat(acc_temp_list, dim=\"nn_member_id\")\n",
    "    acc_agg[key] = aggregate_acc(acc[key], dim=(\"x\",\"y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(config_cesm.ANALYSIS_RESULTS_DIRECTORY, \"exp1_inputs\")\n",
    "\n",
    "for config in acc:\n",
    "    acc[config].to_netcdf(os.path.join(save_dir, f\"ACC_{config}.nc\"))\n",
    "    acc_agg[config].to_netcdf(os.path.join(save_dir, f\"ACC_agg_{config}.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved acc \n",
    "acc = {}\n",
    "acc_agg = {}\n",
    "\n",
    "save_dir = os.path.join(config_cesm.ANALYSIS_RESULTS_DIRECTORY, \"exp1_inputs\")\n",
    "for key in [\"input2\", \"input3a\", \"input3a_dev\", \"input3a_std\"]:\n",
    "    acc[key] = xr.open_dataset(os.path.join(save_dir, f\"ACC_{key}.nc\"))[\"__xarray_dataarray_variable__\"]\n",
    "    acc_agg[key] = xr.open_dataset(os.path.join(save_dir, f\"ACC_agg_{key}.nc\"))[\"__xarray_dataarray_variable__\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_ds = {}\n",
    "\n",
    "for k in [\"input3a\", \"input3a_dev\", \"input3a_std\"]: \n",
    "    print(f\"Computing bootstrap significance test for {k}\")\n",
    "\n",
    "    significance_ds[k] = bootstrap_acc_significance(acc[\"input2\"], acc[k])\n",
    "\n",
    "for k, ds in significance_ds.items():\n",
    "    significance_ds[k] = roll_acc(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(7,6))\n",
    "\n",
    "x = np.arange(13)\n",
    "y = np.arange(7)\n",
    "x_centers = (x[:-1] + x[1:]) / 2\n",
    "y_centers = (y[:-1] + y[1:]) / 2\n",
    "\n",
    "acc_zscore_norm = acc_agg[\"input3a_std\"].mean(\"nn_member_id\")\n",
    "acc_minmax_norm = acc_agg[\"input3a\"].mean(\"nn_member_id\")\n",
    "acc_nonorm = acc_agg[\"input3a_dev\"].mean(\"nn_member_id\")\n",
    "acc_sic_only = acc_agg[\"input2\"].mean(\"nn_member_id\")\n",
    "\n",
    "cax = axs[0,0].pcolormesh(x, y, acc_zscore_norm, cmap='Spectral', shading='flat', vmin=0, vmax=1)\n",
    "axs[0,0].set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "axs[0,0].set_ylabel(\"Lead time\")\n",
    "axs[0,0].set_title(f\"Sea ice + sst (z-score norm)\")\n",
    "\n",
    "axs[1,0].pcolormesh(x, y, acc_minmax_norm, cmap='Spectral', shading='flat', vmin=0, vmax=1)\n",
    "axs[1,0].set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "axs[1,0].set_ylabel(\"Lead time\")\n",
    "axs[1,0].set_title(f\"Sea ice + sst (min-max norm)\")\n",
    "\n",
    "axs[2,0].pcolormesh(x, y, acc_nonorm, cmap='Spectral', shading='flat', vmin=0, vmax=1)\n",
    "axs[2,0].set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "axs[2,0].set_ylabel(\"Lead time\")\n",
    "axs[2,0].set_title(f\"Sea ice + sst (no norm)\")\n",
    "\n",
    "cax2 = axs[0,1].pcolormesh(x, y, 100 * (acc_zscore_norm - acc_sic_only) / acc_sic_only,\n",
    "                    cmap='RdBu', shading='flat', vmin=-15, vmax=15)\n",
    "axs[0,1].set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "axs[0,1].set_ylabel(\"Lead time\")\n",
    "axs[0,1].set_title(f\"ACC diff from sea ice only\")\n",
    "significance_mask = (significance_ds[\"input3a_std\"].p_value > P_VALUE_CUTOFF).astype(int)\n",
    "add_hatching(axs[0,1], significance_mask, x, y)\n",
    "\n",
    "axs[1,1].pcolormesh(x, y, 100 * (acc_minmax_norm - acc_sic_only) / acc_sic_only,\n",
    "                    cmap='RdBu', shading='flat', vmin=-15, vmax=15)\n",
    "axs[1,1].set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "axs[1,1].set_ylabel(\"Lead time\")\n",
    "axs[1,1].set_title(f\"ACC diff from sea ice only\")\n",
    "significance_mask = (significance_ds[\"input3a\"].p_value > P_VALUE_CUTOFF).astype(int)\n",
    "add_hatching(axs[1,1], significance_mask, x, y)\n",
    "\n",
    "axs[2,1].pcolormesh(x, y, 100 * (acc_nonorm - acc_sic_only) / acc_sic_only,\n",
    "                    cmap='RdBu', shading='flat', vmin=-15, vmax=15)\n",
    "axs[2,1].set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "axs[2,1].set_ylabel(\"Lead time\")\n",
    "axs[2,1].set_title(f\"ACC diff from sea ice only\")\n",
    "significance_mask = (significance_ds[\"input3a_dev\"].p_value > P_VALUE_CUTOFF).astype(int)\n",
    "add_hatching(axs[2,1], significance_mask, x, y)\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        axs[i,j].set_xticks(x_centers, labels=[\"J\",\"F\",\"M\",\"A\",\"M\",\"J\",\"J\",\"A\",\"S\",\"O\",\"N\",\"D\"])\n",
    "\n",
    "cbar_ax = fig.add_axes([0.1, -0.05, 0.35, 0.02])\n",
    "cbar_ax2 = fig.add_axes([0.6, -0.05, 0.35, 0.02])\n",
    "\n",
    "plt.colorbar(cax, cax=cbar_ax, label=r'ACC', orientation='horizontal')\n",
    "plt.colorbar(cax2, cax=cbar_ax2, label=r'Percent change (%)', orientation='horizontal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/cesm/exp1_ACC_diff_sst_norm.jpg\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## noise experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiment_configs.exp1_inputs import input_noise\n",
    "\n",
    "cdict = load_globals(input_noise)\n",
    "climatology_broadcast = get_broadcast_climatology(cdict, \"test\")\n",
    "targets = load_targets(cdict, \"test\", add_climatology_to_anomaly=False)\n",
    "\n",
    "num_nn_ens_members = 5\n",
    "pred = load_model_predictions(cdict, nn_ens_avg=False, climatology_broadcasted=None, \n",
    "                                add_climatology_to_anomaly=False)\n",
    "\n",
    "acc_temp_list = []\n",
    "for i in range(num_nn_ens_members): \n",
    "    acc_temp = calculate_acc(pred.isel(nn_member_id=i), \n",
    "                        targets, dim=(\"x\",\"y\"), aggregate=False)\n",
    "    acc_temp_list.append(acc_temp)\n",
    "acc_noise = xr.concat(acc_temp_list, dim=\"nn_member_id\")\n",
    "acc_agg_noise = aggregate_acc(acc_noise, dim=(\"x\",\"y\"))\n",
    "\n",
    "save_dir = os.path.join(config_cesm.ANALYSIS_RESULTS_DIRECTORY, \"exp1_inputs\")\n",
    "acc_noise.to_netcdf(os.path.join(save_dir, f\"ACC_input_noise.nc\"))\n",
    "acc_agg_noise.to_netcdf(os.path.join(save_dir, f\"ACC_agg_input_noise.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved acc \n",
    "acc = {}\n",
    "acc_agg = {}\n",
    "\n",
    "save_dir = os.path.join(config_cesm.ANALYSIS_RESULTS_DIRECTORY, \"exp1_inputs\")\n",
    "for key in [\"input2\", \"input_noise\"]:\n",
    "    acc[key] = xr.open_dataset(os.path.join(save_dir, f\"ACC_{key}.nc\"))[\"__xarray_dataarray_variable__\"]\n",
    "    acc_agg[key] = xr.open_dataset(os.path.join(save_dir, f\"ACC_agg_{key}.nc\"))[\"__xarray_dataarray_variable__\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_ds = {}\n",
    "\n",
    "for k in [\"input_noise\",]: \n",
    "    print(f\"Computing bootstrap significance test for {k}\")\n",
    "\n",
    "    significance_ds[k] = bootstrap_acc_significance(acc[\"input2\"], acc[k])\n",
    "\n",
    "for k, ds in significance_ds.items():\n",
    "    significance_ds[k] = roll_acc(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(7, 2))\n",
    "\n",
    "x = np.arange(13)\n",
    "y = np.arange(7)\n",
    "x_centers = (x[:-1] + x[1:]) / 2\n",
    "y_centers = (y[:-1] + y[1:]) / 2\n",
    "\n",
    "acc_noise = acc_agg[\"input_noise\"].mean(\"nn_member_id\")\n",
    "acc_sic_only = acc_agg[\"input2\"].mean(\"nn_member_id\")\n",
    "\n",
    "cax = axs[0].pcolormesh(x, y, acc_noise, cmap='Spectral', shading='flat', vmin=0, vmax=1)\n",
    "axs[0].set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "axs[0].set_ylabel(\"Lead time\")\n",
    "axs[0].set_title(f\"Sea ice + 6 channels of noise\")\n",
    "\n",
    "cax2 = axs[1].pcolormesh(x, y, 100 * (acc_noise - acc_sic_only) / acc_sic_only,\n",
    "                    cmap='RdBu', shading='flat', vmin=-15, vmax=15)\n",
    "axs[1].set_yticks(y_centers, labels=np.arange(1,7,1))\n",
    "axs[1].set_ylabel(\"Lead time\")\n",
    "axs[1].set_title(f\"ACC diff from sea ice only\")\n",
    "significance_mask = (significance_ds[\"input_noise\"].p_value > P_VALUE_CUTOFF).astype(int)\n",
    "add_hatching(axs[1], significance_mask, x, y)\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].set_xticks(x_centers, labels=[\"J\",\"F\",\"M\",\"A\",\"M\",\"J\",\"J\",\"A\",\"S\",\"O\",\"N\",\"D\"])\n",
    "\n",
    "cbar_ax = fig.add_axes([0.1, -0.05, 0.35, 0.05])\n",
    "cbar_ax2 = fig.add_axes([0.6, -0.05, 0.35, 0.05])\n",
    "\n",
    "plt.colorbar(cax, cax=cbar_ax, label=r'ACC', orientation='horizontal')\n",
    "plt.colorbar(cax2, cax=cbar_ax2, label=r'Percent change (%)', orientation='horizontal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/cesm/exp1_ACC_diff_noise.jpg\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal dependence of ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### composite analysis\n",
    "Here we select instances where ACC of input4 exceeds the ACC of input2 by at least `diff_thresh=0.3`. The visualizations are for initialization in October, so that we capture the  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_members = ['r2i1251p1f1', 'r2i1281p1f1', 'r2i1301p1f1', 'r3i1041p1f1']\n",
    "data_dir = '/scratch/users/yucli/cesm_data_processed/data_pairs/seaice_plus_temp_plus_atm_minmax'\n",
    "\n",
    "inputs_da = []\n",
    "for member_id in test_members: \n",
    "    inputs_da.append(xr.open_dataset(os.path.join(data_dir, f\"inputs_member_{member_id}.nc\")))\n",
    "\n",
    "inputs_da = xr.concat(inputs_da, dim=\"member_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_diff_all = acc[\"input4\"].mean(\"nn_member_id\") - acc[\"input2\"].mean(\"nn_member_id\")\n",
    "\n",
    "diff_thresh = 0.3\n",
    "acc_diff = acc_diff_all.where(acc_diff_all > diff_thresh, drop=True)\n",
    "mask = acc_diff.notnull().any(dim=\"lead_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_subset = inputs_da.where(mask, drop=True).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_da = []\n",
    "for member_id in test_members: \n",
    "    targets_da.append(xr.open_dataset(os.path.join(data_dir, f\"targets_member_{member_id}.nc\")))\n",
    "\n",
    "targets_da = xr.concat(targets_da, dim=\"member_id\")\n",
    "targets_subset = targets_da.where(mask, drop=True).data\n",
    "\n",
    "month_init_targets = targets_subset.where(targets_subset.start_prediction_month.dt.month == 10, drop=True).mean((\"member_id\", \"start_prediction_month\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_init_inputs = inputs_subset.where(inputs_subset.start_prediction_month.dt.month == 10, drop=True)\n",
    "print(month_init_inputs[:,:,0,0,0].notnull().sum().values)\n",
    "month_init_inputs = month_init_inputs.mean((\"member_id\", \"start_prediction_month\"))\n",
    "\n",
    "fig, axs = plt.subplots(nrows=6, ncols=6, figsize=(12,12), sharex=True, sharey=True)\n",
    "\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i in range(30):\n",
    "    axs[i].pcolormesh(month_init_inputs.isel(channel=i), vmin=-0.1, vmax=0.1, cmap=\"RdBu_r\")\n",
    "    axs[i].set_title(month_init_inputs.channel[i].values)\n",
    "\n",
    "for i in range(30, 36): \n",
    "    lead = i - 30\n",
    "    axs[i].pcolormesh(month_init_targets.isel(lead_time=lead), vmin=-0.1, vmax=0.1, cmap=\"RdBu_r\")\n",
    "    axs[i].set_title(f\"Target (lead {lead + 1})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2 = load_model_predictions(load_globals(input2), nn_ens_avg=False, climatology_broadcasted=None, \n",
    "                                add_climatology_to_anomaly=False)\n",
    "pred_4 = load_model_predictions(load_globals(input4), nn_ens_avg=False, climatology_broadcasted=None, \n",
    "                                add_climatology_to_anomaly=False)\n",
    "\n",
    "pred_2_subset = pred_2.where(mask, drop=True).mean(\"nn_member_id\")\n",
    "pred_4_subset = pred_4.where(mask, drop=True).mean(\"nn_member_id\")\n",
    "\n",
    "month_init_pred2 = pred_2_subset.where(pred_2_subset.start_prediction_month.dt.month == 10, drop=True).mean((\"member_id\", \"start_prediction_month\"))\n",
    "month_init_pred4 = pred_4_subset.where(pred_4_subset.start_prediction_month.dt.month == 10, drop=True).mean((\"member_id\", \"start_prediction_month\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "\n",
    "month_init_inputs = inputs_subset.where(inputs_subset.start_prediction_month.dt.month == 10, drop=True)\n",
    "print(month_init_inputs[:,:,0,0,0].notnull().sum().values)\n",
    "month_init_inputs = month_init_inputs.mean((\"member_id\", \"start_prediction_month\"))\n",
    "\n",
    "lon = reference_grid.lon.data\n",
    "lat = reference_grid.lat.data\n",
    "\n",
    "fig, axs = plt.subplots(nrows=8, ncols=6, figsize=(12,16), sharex=True, sharey=True,\n",
    "                        subplot_kw={'projection': ccrs.SouthPolarStereo()})\n",
    "\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i in range(30):\n",
    "    axs[i].pcolormesh(lon, lat, month_init_inputs.isel(channel=i), transform=ccrs.PlateCarree(), vmin=-0.1, vmax=0.1, cmap=\"RdBu_r\")\n",
    "    axs[i].set_title(month_init_inputs.channel[i].values)\n",
    "\n",
    "for i in range(30, 36): \n",
    "    lead = i - 30\n",
    "    axs[i].pcolormesh(lon, lat, month_init_targets.isel(lead_time=lead), transform=ccrs.PlateCarree(), vmin=-0.1, vmax=0.1, cmap=\"RdBu_r\")\n",
    "    axs[i].set_title(f\"Target (lead {lead + 1})\")\n",
    "\n",
    "for i in range(36, 42):\n",
    "    axs[i].pcolormesh(lon, lat, month_init_pred2.isel(lead_time=i-36),transform=ccrs.PlateCarree(), vmin=-0.1, vmax=0.1, cmap=\"RdBu_r\")\n",
    "    axs[i].set_title(f\"input1 pred\")\n",
    "\n",
    "for i in range(42, 48):\n",
    "    axs[i].pcolormesh(lon, lat, month_init_pred4.isel(lead_time=i-42), transform=ccrs.PlateCarree(), vmin=-0.1, vmax=0.1, cmap=\"RdBu_r\")\n",
    "    axs[i].set_title(f\"input3 pred\")\n",
    "\n",
    "for i in range(0, 48):\n",
    "    axs[i].coastlines()\n",
    "\n",
    "plt.savefig(\"figures/cesm/exp1_inputs_composite.jpg\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vars = [\"psl_lag1\", \"icefrac_lag1\", \"geopotential_lag1\", \"temp_lag1\"]\n",
    "\n",
    "eofs_dict = {}\n",
    "pcs_dict = {}\n",
    "var_exp_dict = {}\n",
    "n_components = 4\n",
    "\n",
    "for input_var in input_vars:\n",
    "    stacked = inputs_da[\"data\"].sel(channel=input_var).stack(samples=(\"member_id\", \"start_prediction_month\"))\n",
    "    nx, ny, nsamples = stacked.shape\n",
    "\n",
    "    anom_matrix = (stacked - stacked.mean((\"x\",\"y\"))).values.reshape(nx * ny, nsamples).T\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(anom_matrix)\n",
    "    pcs = pca.transform(anom_matrix)\n",
    "    eofs_flat = pca.components_ \n",
    "    eofs = eofs_flat.reshape(n_components, ny, nx)\n",
    "\n",
    "    eofs_dict[input_var] = xr.DataArray(\n",
    "        eofs,\n",
    "        dims=(\"mode\", \"y\", \"x\"),\n",
    "        coords={\"mode\": np.arange(n_components), \"y\": stacked.y, \"x\": stacked.x},\n",
    "        name=\"EOF\"\n",
    "    )\n",
    "    \n",
    "    samples_index = stacked[\"samples\"]\n",
    "    pcs_dict[input_var] = xr.DataArray(\n",
    "        pcs,\n",
    "        dims=(\"samples\", \"mode\"),\n",
    "        coords={\"samples\": samples_index, \"mode\": np.arange(n_components)},\n",
    "        name=\"PC\"\n",
    "    ).unstack(\"samples\")\n",
    "\n",
    "    var_exp_dict[input_var] = xr.DataArray(\n",
    "        pca.explained_variance_ratio_,\n",
    "        dims=(\"mode\",),\n",
    "        coords={\"mode\": np.arange(n_components)},\n",
    "        name=\"VarianceExplained\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "plt.pcolormesh(eofs_dict[\"psl_lag1\"].isel(mode=0), cmap=\"RdBu\")\n",
    "plt.title(\"Sea level pressure (leading mode)\")\n",
    "plt.colorbar()\n",
    "plt.savefig(\"figures/illustrations/sam.jpg\",dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = pcs_dict[\"icefrac_lag1\"].start_prediction_month\n",
    "month = 10\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(8,5), nrows=3, ncols=6, sharex=True)\n",
    "\n",
    "cmap = plt.get_cmap(\"plasma\").copy()\n",
    "\n",
    "psl_pc = np.abs(pcs_dict[\"psl_lag1\"].isel(mode=0).where(time.dt.month == month, drop=True).values.flatten())\n",
    "acc_input2 = acc[\"input2\"].mean(\"nn_member_id\").where(time.dt.month == month, drop=True)\n",
    "acc_input4 = acc[\"input4\"].mean(\"nn_member_id\").where(time.dt.month == month, drop=True)\n",
    "\n",
    "months = ['Oct', 'Nov', 'Dec', 'Jan', 'Feb', 'Mar']\n",
    "for i in range(6):\n",
    "    axs[0,i].hist2d(psl_pc, acc_input2.isel(lead_time=i).values.flatten(),\n",
    "                    bins=[15,15], density=True, cmap=\"cubehelix_r\")\n",
    "\n",
    "    axs[1,i].hist2d(psl_pc, acc_input4.isel(lead_time=i).values.flatten(), \n",
    "                    bins=[15,15], density=True, cmap=\"cubehelix_r\")\n",
    "\n",
    "    axs[2,i].hist2d(psl_pc, (acc_input4 - acc_input2).isel(lead_time=i).values.flatten(), \n",
    "                    bins=[15,19], density=True, cmap=\"cubehelix_r\")\n",
    "\n",
    "    axs[0,i].set_ylim([-0.25, 1])\n",
    "    axs[1,i].set_ylim([-0.25, 1])\n",
    "    axs[2,i].set_ylim([-0.4, 0.4])\n",
    "\n",
    "    for j in range(3):\n",
    "        axs[j,i].set_xlim([0, 20])\n",
    "        axs[j,i].set_xticks([0, 10, 20])\n",
    "        \n",
    "        if i > 0:\n",
    "            axs[j,i].set_yticklabels([])\n",
    "        \n",
    "        axs[j,i].grid(color='0.3')\n",
    "    \n",
    "    axs[0,0].set_ylabel(\"ACC (input1)\") #this uses the same nomenclature as the paper \n",
    "    axs[1,0].set_ylabel(\"ACC (input3)\") \n",
    "    axs[2,0].set_ylabel(\"ACC difference\") \n",
    "    axs[2,i].set_xlabel(rf\"abs($PC_1^{{\\mathrm{{psl}}}}$)\")\n",
    "    axs[0,i].set_title(f\"Lead {i+1} ({months[i]})\", fontsize=11)\n",
    "\n",
    "plt.savefig(\"figures/cesm/exp1_SAM_ACC_joint_dist_sep_init.jpg\", bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_exp_dict[\"psl_lag1\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sicpred_env_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
