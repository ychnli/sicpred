{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "DATA_DIRECTORY = '/oak/stanford/groups/earlew/yuchen'\n",
    "\n",
    "RAW_DATA_DIRECTORY = '/scratch/users/yucli/cesm_data'\n",
    "\n",
    "# Renamed variable names \n",
    "VAR_NAMES = [\"icefrac\", \"icethick\", \"temp\", \"geopotential\", \"psl\", \"lw_flux\", \"sw_flux\", \"ua\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "class CESM_SeaIceDataset(Dataset):\n",
    "    def __init__(self, data_dir, ensemble_members, transform=None):\n",
    "        \"\"\"\n",
    "        Param:\n",
    "            data_dir (str): Path to the directory containing model-ready input and target files \n",
    "            ensemble_members (list): List of ensemble member ids (ripf notation)\n",
    "            transform (callable, optional): Optional transform to apply to the samples.\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.ensemble_members = ensemble_members\n",
    "        self.transform = transform\n",
    "\n",
    "        # Build a global index of samples\n",
    "        self.samples = []\n",
    "        for member in ensemble_members:\n",
    "            input_file = os.path.join(data_dir, f\"inputs_member_{member}.nc\")\n",
    "            with xr.open_dataset(input_file) as ds:\n",
    "                for start_idx in range(len(ds[\"start_prediction_month\"])):\n",
    "                    self.samples.append((member, start_idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        member, start_idx = self.samples[idx]\n",
    "        input_file = os.path.join(self.data_dir, f\"inputs_member_{member}.nc\")\n",
    "        target_file = os.path.join(self.data_dir, f\"targets_member_{member}.nc\")\n",
    "\n",
    "        # Load the specific sample lazily\n",
    "        with xr.open_dataset(input_file) as input_ds:\n",
    "            input_sample = input_ds[\"data\"].isel(start_prediction_month=start_idx).values\n",
    "\n",
    "        with xr.open_dataset(target_file) as target_ds:\n",
    "            target_sample = target_ds[\"data\"].isel(start_prediction_month=start_idx).values\n",
    "\n",
    "        sample = {\"input\": torch.tensor(input_sample, dtype=torch.float32),\n",
    "                  \"target\": torch.tensor(target_sample, dtype=torch.float32)}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "data_dir = \"/scratch/users/yucli/model-ready_cesm_data/data_pairs_setting1\"\n",
    "ensemble_members = np.unique([name.split(\"_\")[2].split(\".\")[0] for name in os.listdir(data_dir)])\n",
    "\n",
    "\n",
    "dataset = CESM_SeaIceDataset(data_dir, ensemble_members)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeaIceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_directory, configuration, split_array, start_prediction_months, \\\n",
    "                split_type='train', target_shape=(80, 80), mode=\"regression\", class_splits=None):\n",
    "        self.data_directory = data_directory\n",
    "        self.configuration = configuration\n",
    "        self.split_array = split_array\n",
    "        self.start_prediction_months = start_prediction_months\n",
    "        self.split_type = split_type\n",
    "        self.target_shape = target_shape\n",
    "        self.class_splits = class_splits\n",
    "        self.mode = mode\n",
    "\n",
    "        # Open the HDF5 files\n",
    "        self.inputs_file = h5py.File(f\"{data_directory}/inputs_{configuration}.h5\", 'r')\n",
    "\n",
    "        if \"sicanom\" in configuration: \n",
    "            targets_configuration = \"anom_regression\" \n",
    "        else: \n",
    "            targets_configuration = \"regression\"\n",
    "\n",
    "        self.targets_file = h5py.File(f\"{data_directory}/targets_{targets_configuration}.h5\", 'r')\n",
    "        \n",
    "        self.inputs = self.inputs_file[f\"inputs_{configuration}\"]\n",
    "        self.targets = self.targets_file['targets_sea_ice_only']\n",
    "\n",
    "        self.n_samples, self.n_channels, self.n_y, self.n_x = self.inputs.shape\n",
    "        \n",
    "        # Get indices for the specified split type\n",
    "        self.indices = np.where(self.split_array == split_type)[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        actual_idx = self.indices[idx]\n",
    "        input_data = self.inputs[actual_idx]\n",
    "        target_data = self.targets[actual_idx]\n",
    "        start_prediction_month = self.start_prediction_months[actual_idx]\n",
    "\n",
    "        # Pad input_data and target_data to the target shape\n",
    "        pad_y = self.target_shape[0] - self.n_y\n",
    "        pad_x = self.target_shape[1] - self.n_x\n",
    "        input_data = np.pad(input_data, ((0, 0), (pad_y//2, pad_y//2), (pad_x//2, pad_x//2)), mode='constant', constant_values=0)\n",
    "        target_data = np.pad(target_data, ((0, 0), (pad_y//2, pad_y//2), (pad_x//2, pad_x//2)), mode='constant', constant_values=0)\n",
    "\n",
    "        # If we are doing classification, then discretise the target data\n",
    "        if self.mode == \"classification\":\n",
    "            if self.class_splits is None:\n",
    "                raise ValueError(\"need to specify a monotonically increasing list class_splits denoting class boundaries\")\n",
    "\n",
    "            # check if class_split is monotonically increasing\n",
    "            if len(self.class_splits) > 1 and np.any(np.diff(self.class_splits) < 0): \n",
    "                raise ValueError(\"class_splits needs to be monotonically increasing\")\n",
    "\n",
    "            bounds = [] # bounds for classes\n",
    "            for i,class_split in enumerate(self.class_splits): \n",
    "                if i == 0: \n",
    "                    bounds.append([0, class_split])\n",
    "                if i == len(self.class_splits) - 1: \n",
    "                    bounds.append([class_split, 1])\n",
    "                else: \n",
    "                    bounds.append([class_split, self.class_splits[i+1]])\n",
    "            \n",
    "            target_classes_data = np.zeros_like(target_data) \n",
    "            target_classes_data = target_classes_data[np.newaxis,:,:,:]\n",
    "            target_classes_data = np.repeat(target_classes_data, len(bounds), axis=0)\n",
    "            for i,bound in enumerate(bounds): \n",
    "                if i == len(bounds) - 1: \n",
    "                    target_classes_data[i,:,:,:] = np.logical_and(target_data >= bound[0], target_data <= bound[1]).astype(int)\n",
    "                else:\n",
    "                    target_classes_data[i,:,:,:] = np.logical_and(target_data >= bound[0], target_data < bound[1]).astype(int)\n",
    "            \n",
    "            target_data = target_classes_data \n",
    "\n",
    "        input_tensor = torch.tensor(input_data, dtype=torch.float32)\n",
    "        target_tensor = torch.tensor(target_data, dtype=torch.float32)\n",
    "\n",
    "        # Get the target months for this sample\n",
    "        target_months = pd.date_range(start=start_prediction_month, end=start_prediction_month + pd.DateOffset(months=5), freq=\"MS\")\n",
    "        target_months = target_months.month.to_numpy()\n",
    "        \n",
    "        return input_tensor, target_tensor, target_months\n",
    "\n",
    "    def __del__(self):\n",
    "        self.inputs_file.close()\n",
    "        self.targets_file.close()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sicpred_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
